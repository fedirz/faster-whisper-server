# TODO: https://docs.astral.sh/uv/guides/integration/docker/#configuring-watch-with-docker-compose
include:
  - observability-compose.yaml
services:
  faster-whisper-server-cuda:
    image: fedirz/faster-whisper-server:latest-cuda
    build:
      dockerfile: Dockerfile.cuda
      context: .
      platforms:
        - linux/amd64
        - linux/arm64
    restart: unless-stopped
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
    develop:
      watch:
        - path: faster_whisper_server
          action: rebuild
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
              # If you have CDI feature enabled use the following instead
              # https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/cdi-support.html
              # https://docs.docker.com/reference/cli/dockerd/#enable-cdi-devices
              # - driver: cdi
              #   device_ids:
              #   - nvidia.com/gpu=all
  faster-whisper-server-cpu:
    image: fedirz/faster-whisper-server:latest-cpu
    build:
      dockerfile: Dockerfile.cpu
      context: .
      platforms:
        - linux/amd64
        - linux/arm64
    restart: unless-stopped
    ports:
      - 8000:8000
    volumes:
      - hugging_face_cache:/root/.cache/huggingface
    develop:
      watch:
        - path: faster_whisper_server
          action: rebuild
volumes:
  hugging_face_cache:
