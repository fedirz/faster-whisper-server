from typing import Annotated, Any, Literal

from openai.types.beta.realtime import (
    ConversationCreatedEvent as OpenAIConversationCreatedEvent,
)
from openai.types.beta.realtime import (
    ConversationItemDeletedEvent as OpenAIConversationItemDeletedEvent,
)
from openai.types.beta.realtime import (
    ConversationItemDeleteEvent,
    ConversationItemTruncateEvent,
    InputAudioBufferAppendEvent,
    InputAudioBufferClearEvent,
    InputAudioBufferCommitEvent,
    RateLimitsUpdatedEvent,
    ResponseCancelEvent,
    ResponseCreateEvent,
    SessionUpdateEvent,
)
from openai.types.beta.realtime import (
    ConversationItemInputAudioTranscriptionCompletedEvent as OpenAIConversationItemInputAudioTranscriptionCompletedEvent,
)
from openai.types.beta.realtime import (
    ConversationItemInputAudioTranscriptionFailedEvent as OpenAIConversationItemInputAudioTranscriptionFailedEvent,
)
from openai.types.beta.realtime import (
    ConversationItemTruncatedEvent as OpenAIConversationItemTruncatedEvent,
)
from openai.types.beta.realtime import (
    ErrorEvent as OpenAIErrorEvent,
)
from openai.types.beta.realtime import (
    InputAudioBufferClearedEvent as OpenAIInputAudioBufferClearedEvent,
)
from openai.types.beta.realtime import (
    InputAudioBufferSpeechStartedEvent as OpenAIInputAudioBufferSpeechStartedEvent,
)
from openai.types.beta.realtime import (
    InputAudioBufferSpeechStoppedEvent as OpenAIInputAudioBufferSpeechStoppedEvent,
)
from openai.types.beta.realtime import (
    ResponseAudioDeltaEvent as OpenAIResponseAudioDeltaEvent,
)
from openai.types.beta.realtime import (
    ResponseAudioDoneEvent as OpenAIResponseAudioDoneEvent,
)
from openai.types.beta.realtime import (
    ResponseAudioTranscriptDeltaEvent as OpenAIResponseAudioTranscriptDeltaEvent,
)
from openai.types.beta.realtime import (
    ResponseAudioTranscriptDoneEvent as OpenAIResponseAudioTranscriptDoneEvent,
)
from openai.types.beta.realtime import (
    ResponseFunctionCallArgumentsDeltaEvent as OpenAIResponseFunctionCallArgumentsDeltaEvent,
)
from openai.types.beta.realtime import (
    ResponseFunctionCallArgumentsDoneEvent as OpenAIResponseFunctionCallArgumentsDoneEvent,
)
from openai.types.beta.realtime import (
    ResponseTextDeltaEvent as OpenAIResponseTextDeltaEvent,
)
from openai.types.beta.realtime import (
    ResponseTextDoneEvent as OpenAIResponseTextDoneEvent,
)
from pydantic import BaseModel, Discriminator, Field, model_validator
from pydantic.type_adapter import TypeAdapter

from speaches.realtime.utils import generate_event_id, generate_item_id


class PartText(BaseModel):
    type: Literal["text"] = "text"
    text: str


class PartAudio(BaseModel):
    type: Literal["audio"] = "audio"
    transcript: str


type Part = PartText | PartAudio


# TODO: document that this type is fully custom and doesn't exist in the OpenAI API
class ConversationItemContentAudio(BaseModel):
    type: Literal["audio"] = "audio"
    transcript: str
    audio: str

    def to_part(self) -> PartAudio:
        return PartAudio(transcript=self.transcript)


class ConversationItemContentInputAudio(BaseModel):  # TODO: document the weirdness about this type
    type: Literal["input_audio"] = "input_audio"
    transcript: str | None
    # audio: str


class ConversationItemContentItemReference(BaseModel):
    type: Literal["item_reference"] = "item_reference"
    id: str


class ConversationItemContentText(BaseModel):
    type: Literal["text"] = "text"
    text: str

    def to_part(self) -> PartText:
        return PartText(text=self.text)


class ConversationItemContentInputText(BaseModel):
    type: Literal["input_text"] = "input_text"
    text: str


type ConversationItemContent = (
    ConversationItemContentInputText
    | ConversationItemContentInputAudio
    | ConversationItemContentItemReference
    | ConversationItemContentText
    | ConversationItemContentAudio
)


class BaseConversationItem(BaseModel):
    id: str = Field(default_factory=generate_item_id)
    object: Literal["realtime.item"] = "realtime.item"
    status: Literal["incomplete", "completed"]



class ConversationItemMessage(BaseConversationItem):
    type: Literal["message"] = "message"
    role: Literal["assistant", "user", "system"]
    content: list[ConversationItemContent]  # TODO: custom type


class ConversationItemFunctionCall(BaseConversationItem):
    type: Literal["function_call"] = "function_call"
    call_id: str
    name: str
    arguments: str


class ConversationItemFunctionCallOutput(BaseConversationItem):
    type: Literal["function_call_output"] = "function_call_output"
    call_id: str
    output: str


# NOTE: server can't generate "function_call_output"
type ServerConversationItem = ConversationItemMessage | ConversationItemFunctionCall
type ConversationItem = ConversationItemMessage | ConversationItemFunctionCall | ConversationItemFunctionCallOutput


class ConversationItemCreateEvent(BaseModel):
    type: Literal["conversation.item.create"] = "conversation.item.create"
    event_id: str = Field(default_factory=generate_event_id)
    previous_item_id: str | None
    item: ConversationItem


class ConversationItemCreatedEvent(BaseModel):
    type: Literal["conversation.item.created"] = "conversation.item.created"
    event_id: str = Field(default_factory=generate_event_id)
    item: ConversationItem
    previous_item_id: str | None


class ResponseOutputItemAddedEvent(BaseModel):
    type: Literal["response.output_item.added"] = "response.output_item.added"
    event_id: str = Field(default_factory=generate_event_id)
    output_index: int = 0
    response_id: str
    item: ServerConversationItem


class ResponseOutputItemDoneEvent(BaseModel):
    type: Literal["response.output_item.done"] = "response.output_item.done"
    event_id: str = Field(default_factory=generate_event_id)
    output_index: int = 0
    response_id: str
    item: ServerConversationItem


class RealtimeResponse(BaseModel):
    id: str
    status: Literal["completed", "cancelled", "failed", "incomplete"]
    output: list[ServerConversationItem]
    modalities: list[Literal["text", "audio"]]
    object: Literal["realtime.response"] = "realtime.response"
    # TODO: add and support additional fields


class ResponseCreatedEvent(BaseModel):
    type: Literal["response.created"] = "response.created"
    event_id: str = Field(default_factory=generate_event_id)
    response: RealtimeResponse


class ResponseDoneEvent(BaseModel):
    type: Literal["response.done"] = "response.done"
    event_id: str = Field(default_factory=generate_event_id)
    response: RealtimeResponse


# Same as openai.types.beta.realtime.session_update_event.SessionTurnDetection but with all the fields made non-nullable
class TurnDetection(BaseModel):
    create_response: bool
    prefix_padding_ms: int = 0  # HACK: without this setting the `turn_detection` when it's null will not work with the current implementation of session updates
    silence_duration_ms: int
    threshold: float = Field(..., ge=0.0, le=1.0)
    type: Literal["server_vad"] = "server_vad"


class InputAudioTranscription(BaseModel):
    model: str


type AudioFormat = Literal["pcm16", "g711_ulaw", "g711_alaw"]
type Modality = Literal["text", "audio"]


class Tool(BaseModel):
    name: str
    description: str
    parameters: dict
    type: Literal["function"] = "function"


# ChatCompletionToolChoiceOptionParam: TypeAlias = Union[
#     Literal["none", "auto", "required"], ChatCompletionNamedToolChoiceParam
# ]


class Function(BaseModel):
    name: str


class NamedToolChoice(BaseModel):
    function: Function
    type: Literal["function"] = "function"


type ToolChoice = Literal["none", "auto", "required"] | NamedToolChoice


class Response(BaseModel):
    conversation: Literal["auto"]  # NOTE: there's also "none" but it's not supported in this implementation
    input: list[ConversationItem]
    instructions: str
    max_response_output_tokens: int | Literal["inf"]
    modalities: list[Modality]
    output_audio_format: AudioFormat
    temperature: float  # TODO: should there be lower and upper bounds?
    tool_choice: ToolChoice
    tools: list[Tool]
    voice: str


# TODO: which defaults should be set (if any)?
class Session(BaseModel):
    id: str  # TODO: should this be auto-generated?
    input_audio_format: AudioFormat
    input_audio_transcription: InputAudioTranscription  # NOTE: according to the spec None is a valid value here, but in this implementation it would be impossible to do anything without a transcription model
    instructions: str
    max_response_output_tokens: int | Literal["inf"]
    modalities: list[Modality]
    model: str
    output_audio_format: AudioFormat
    temperature: float  # TODO: should there be lower and upper bounds?
    tool_choice: ToolChoice
    tools: list[Tool]
    turn_detection: TurnDetection | None
    voice: str


class SessionCreatedEvent(BaseModel):
    type: Literal["session.created"] = "session.created"
    event_id: str = Field(default_factory=generate_event_id)
    session: Session


class SessionUpdatedEvent(BaseModel):
    type: Literal["session.updated"] = "session.updated"
    event_id: str = Field(default_factory=generate_event_id)
    session: Session


class InputAudioBufferCommittedEvent(BaseModel):
    type: Literal["input_audio_buffer.committed"] = "input_audio_buffer.committed"
    event_id: str = Field(default_factory=generate_event_id)
    item_id: str
    previous_item_id: str | None


# The following classes are the same as the ones in openai.types.beta.realtime but with fields assigned some default values. This is to reduce the amount of boilerplate code when creating these events.


class InputAudioBufferSpeechStartedEvent(OpenAIInputAudioBufferSpeechStartedEvent):
    type: Literal["input_audio_buffer.speech_started"] = "input_audio_buffer.speech_started"
    event_id: str = Field(default_factory=generate_event_id)


class InputAudioBufferSpeechStoppedEvent(OpenAIInputAudioBufferSpeechStoppedEvent):
    type: Literal["input_audio_buffer.speech_stopped"] = "input_audio_buffer.speech_stopped"
    event_id: str = Field(default_factory=generate_event_id)


class ConversationCreatedEvent(OpenAIConversationCreatedEvent):
    type: Literal["conversation.created"] = "conversation.created"
    event_id: str = Field(default_factory=generate_event_id)


class ConversationItemDeletedEvent(OpenAIConversationItemDeletedEvent):
    type: Literal["conversation.item.deleted"] = "conversation.item.deleted"
    event_id: str = Field(default_factory=generate_event_id)


class ConversationItemInputAudioTranscriptionCompletedEvent(
    OpenAIConversationItemInputAudioTranscriptionCompletedEvent
):
    type: Literal["conversation.item.input_audio_transcription.completed"] = (
        "conversation.item.input_audio_transcription.completed"
    )
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0


class ConversationItemInputAudioTranscriptionFailedEvent(OpenAIConversationItemInputAudioTranscriptionFailedEvent):
    type: Literal["conversation.item.input_audio_transcription.failed"] = (
        "conversation.item.input_audio_transcription.failed"
    )
    event_id: str = Field(default_factory=generate_event_id)


class InputAudioBufferClearedEvent(OpenAIInputAudioBufferClearedEvent):
    type: Literal["input_audio_buffer.cleared"] = "input_audio_buffer.cleared"
    event_id: str = Field(default_factory=generate_event_id)


class ConversationItemTruncatedEvent(OpenAIConversationItemTruncatedEvent):
    type: Literal["conversation.item.truncated"] = "conversation.item.truncated"
    event_id: str = Field(default_factory=generate_event_id)


class ErrorEvent(OpenAIErrorEvent):
    type: Literal["error"] = "error"
    event_id: str = Field(default_factory=generate_event_id)


class ResponseContentPartAddedEvent(BaseModel):
    type: Literal["response.content_part.added"] = "response.content_part.added"
    event_id: str = Field(default_factory=generate_event_id)
    response_id: str
    item_id: str
    content_index: int = 0
    output_index: int = 0
    part: Part


class ResponseContentPartDoneEvent(BaseModel):
    type: Literal["response.content_part.done"] = "response.content_part.done"
    event_id: str = Field(default_factory=generate_event_id)
    response_id: str
    item_id: str
    content_index: int = 0
    output_index: int = 0
    part: Part


class ResponseTextDeltaEvent(OpenAIResponseTextDeltaEvent):
    type: Literal["response.text.delta"] = "response.text.delta"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseTextDoneEvent(OpenAIResponseTextDoneEvent):
    type: Literal["response.text.done"] = "response.text.done"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseAudioTranscriptDeltaEvent(OpenAIResponseAudioTranscriptDeltaEvent):
    type: Literal["response.audio_transcript.delta"] = "response.audio_transcript.delta"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseAudioDeltaEvent(OpenAIResponseAudioDeltaEvent):
    type: Literal["response.audio.delta"] = "response.audio.delta"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseAudioDoneEvent(OpenAIResponseAudioDoneEvent):
    type: Literal["response.audio.done"] = "response.audio.done"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseAudioTranscriptDoneEvent(OpenAIResponseAudioTranscriptDoneEvent):
    type: Literal["response.audio_transcript.done"] = "response.audio_transcript.done"
    event_id: str = Field(default_factory=generate_event_id)
    content_index: int = 0
    output_index: int = 0


class ResponseFunctionCallArgumentsDeltaEvent(OpenAIResponseFunctionCallArgumentsDeltaEvent):
    type: Literal["response.function_call_arguments.delta"] = "response.function_call_arguments.delta"
    event_id: str = Field(default_factory=generate_event_id)
    output_index: int = 0


class ResponseFunctionCallArgumentsDoneEvent(OpenAIResponseFunctionCallArgumentsDoneEvent):
    type: Literal["response.function_call_arguments.done"] = "response.function_call_arguments.done"
    event_id: str = Field(default_factory=generate_event_id)
    output_index: int = 0


type SessionClientEvent = SessionUpdateEvent
type SessionServerEvent = SessionCreatedEvent | SessionUpdatedEvent


type InputAudioBufferClientEvent = (
    InputAudioBufferAppendEvent | InputAudioBufferCommitEvent | InputAudioBufferClearEvent
)

type InputAudioBufferServerEvent = (
    InputAudioBufferCommittedEvent
    | InputAudioBufferClearedEvent
    | InputAudioBufferSpeechStartedEvent
    | InputAudioBufferSpeechStoppedEvent
)

type ConversationClientEvent = ConversationItemCreateEvent | ConversationItemTruncateEvent | ConversationItemDeleteEvent

type ConversationServerEvent = (
    ConversationCreatedEvent
    | ConversationItemCreatedEvent
    | ConversationItemInputAudioTranscriptionCompletedEvent
    | ConversationItemInputAudioTranscriptionFailedEvent
    | ConversationItemTruncatedEvent
    | ConversationItemDeletedEvent
)


type ResponseClientEvent = ResponseCreateEvent | ResponseCancelEvent

type ResponseContentDeltaEvent = (
    ResponseTextDeltaEvent
    | ResponseAudioTranscriptDeltaEvent
    | ResponseAudioDeltaEvent
    | ResponseFunctionCallArgumentsDeltaEvent
)

type ResponseContentDoneEvent = (
    ResponseTextDoneEvent
    | ResponseAudioTranscriptDoneEvent
    | ResponseAudioDoneEvent
    | ResponseFunctionCallArgumentsDoneEvent
)

type ResponseServerEvent = (
    ResponseCreatedEvent
    | ResponseOutputItemAddedEvent
    | ResponseContentPartAddedEvent
    | ResponseTextDeltaEvent
    | ResponseTextDoneEvent
    | ResponseFunctionCallArgumentsDeltaEvent
    | ResponseFunctionCallArgumentsDoneEvent
    | ResponseAudioTranscriptDeltaEvent
    | ResponseAudioTranscriptDoneEvent
    | ResponseAudioDeltaEvent
    | ResponseAudioDoneEvent
    | ResponseContentPartDoneEvent
    | ResponseOutputItemDoneEvent
    | ResponseDoneEvent
)

# https://platform.openai.com/docs/guides/realtime/overview#events
CLIENT_EVENT_TYPES = {
    "session.update",
    "input_audio_buffer.append",
    "input_audio_buffer.commit",
    "input_audio_buffer.clear",
    "conversation.item.create",
    "conversation.item.truncate",
    "conversation.item.delete",
    "response.create",
    "response.cancel",
}
SERVER_EVENT_TYPES = {
    "error",
    "session.created",
    "session.updated",
    "conversation.created",
    "input_audio_buffer.committed",
    "input_audio_buffer.cleared",
    "input_audio_buffer.speech_started",
    "input_audio_buffer.speech_stopped",
    "conversation.item.created",
    "conversation.item.input_audio_transcription.completed",
    "conversation.item.input_audio_transcription.failed",
    "conversation.item.truncated",
    "conversation.item.deleted",
    "response.created",
    "response.done",
    "response.output_item.added",
    "response.output_item.done",
    "response.content_part.added",
    "response.content_part.done",
    "response.text.delta",
    "response.text.done",
    "response.audio_transcript.delta",
    "response.audio_transcript.done",
    "response.audio.delta",
    "response.audio.done",
    "response.function_call_arguments.delta",
    "response.function_call_arguments.done",
    "rate_limits.updated",
}

ClientEvent = Annotated[
    SessionUpdateEvent | InputAudioBufferClientEvent | ConversationClientEvent | ResponseClientEvent,
    Discriminator("type"),
]

client_event_type_adapter = TypeAdapter[ClientEvent](ClientEvent)

ServerEvent = Annotated[
    SessionServerEvent
    | InputAudioBufferServerEvent
    | ConversationServerEvent
    | ResponseServerEvent
    | ErrorEvent
    | RateLimitsUpdatedEvent,
    Discriminator("type"),
]

server_event_type_adapter = TypeAdapter[ServerEvent](ServerEvent)

Event = ClientEvent | ServerEvent
